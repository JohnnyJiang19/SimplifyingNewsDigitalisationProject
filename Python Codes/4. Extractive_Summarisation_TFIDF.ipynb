{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ISSS609-Text Analytics and Applications Project\n",
    "\n",
    "There will be a list of workbooks for the purpose of this project.\n",
    "\n",
    "1) Data_Preparation_and_Topic_Modelling\n",
    "\n",
    "2) Abstractive_Summarisation\n",
    "\n",
    "3) Extractive_Summarisation_Average_Score\n",
    "\n",
    "4) Extractive_Summarisation_TFIDF\n",
    "\n",
    "5) UI_Preparation\n",
    "\n",
    "### This workbook will cover (4)  Extraction-based summarization based on TF-IDF algorithm.\n",
    "Reference: https://github.com/akashp1712/nlp-akash/blob/master/text-summarization/summarize3.py\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import nltk\n",
    "from nltk import sent_tokenize, word_tokenize, PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load text file and create a PlaintextCorpusReader object\n",
    "file_directory = 'Raw Data/News_content/'\n",
    "filename_pattern = '.+\\.txt'\n",
    "my_corpus = PlaintextCorpusReader(file_directory, filename_pattern)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_frequency_matrix(sentences):\n",
    "    frequency_matrix = {}\n",
    "    stopWords = set(stopwords.words(\"english\"))\n",
    "    ps = PorterStemmer()\n",
    "\n",
    "    for sent in sentences:\n",
    "        freq_table = {}\n",
    "        words = word_tokenize(sent)\n",
    "        for word in words:\n",
    "            word = word.lower()\n",
    "            word = ps.stem(word)\n",
    "            if word in stopWords:\n",
    "                continue\n",
    "\n",
    "            if word in freq_table:\n",
    "                freq_table[word] += 1\n",
    "            else:\n",
    "                freq_table[word] = 1\n",
    "\n",
    "        frequency_matrix[sent[:15]] = freq_table\n",
    "\n",
    "    return frequency_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_tf_matrix(freq_matrix):\n",
    "    tf_matrix = {}\n",
    "\n",
    "    for sent, f_table in freq_matrix.items():\n",
    "        tf_table = {}\n",
    "\n",
    "        count_words_in_sentence = len(f_table)\n",
    "        for word, count in f_table.items():\n",
    "            tf_table[word] = count / count_words_in_sentence\n",
    "\n",
    "        tf_matrix[sent] = tf_table\n",
    "\n",
    "    return tf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_documents_per_words(freq_matrix):\n",
    "    word_per_doc_table = {}\n",
    "\n",
    "    for sent, f_table in freq_matrix.items():\n",
    "        for word, count in f_table.items():\n",
    "            if word in word_per_doc_table:\n",
    "                word_per_doc_table[word] += 1\n",
    "            else:\n",
    "                word_per_doc_table[word] = 1\n",
    "\n",
    "    return word_per_doc_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_idf_matrix(freq_matrix, count_doc_per_words, total_documents):\n",
    "    idf_matrix = {}\n",
    "\n",
    "    for sent, f_table in freq_matrix.items():\n",
    "        idf_table = {}\n",
    "\n",
    "        for word in f_table.keys():\n",
    "            idf_table[word] = math.log10(total_documents / float(count_doc_per_words[word]))\n",
    "\n",
    "        idf_matrix[sent] = idf_table\n",
    "\n",
    "    return idf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_final_matrix(tf_matrix, idf_matrix):\n",
    "    tf_idf_matrix = {}\n",
    "\n",
    "    for (sent1, f_table1), (sent2, f_table2) in zip(tf_matrix.items(), idf_matrix.items()):\n",
    "\n",
    "        tf_idf_table = {}\n",
    "\n",
    "        for (word1, value1), (word2, value2) in zip(f_table1.items(),\n",
    "                                                    f_table2.items()):  # here, keys are the same in both the table\n",
    "            tf_idf_table[word1] = float(value1 * value2)\n",
    "\n",
    "        tf_idf_matrix[sent1] = tf_idf_table\n",
    "\n",
    "    return tf_idf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _score_sentences(tf_idf_matrix) -> dict:\n",
    "    \"\"\"\n",
    "    score a sentence by its word's TF\n",
    "    Basic algorithm: adding the TF frequency of every non-stop word in a sentence divided by total no of words in a sentence.\n",
    "    :rtype: dict\n",
    "    \"\"\"\n",
    "    # TODO: Can you make this multiprocess compatible in python?\n",
    "\n",
    "    sentenceValue = {}\n",
    "\n",
    "    for sent, f_table in tf_idf_matrix.items():\n",
    "        total_score_per_sentence = 0\n",
    "\n",
    "        count_words_in_sentence = len(f_table)\n",
    "        for word, score in f_table.items():\n",
    "            total_score_per_sentence += score\n",
    "\n",
    "        sentenceValue[sent] = total_score_per_sentence / count_words_in_sentence\n",
    "\n",
    "    return sentenceValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _find_average_score(sentenceValue) -> int:\n",
    "    \"\"\"\n",
    "    Find the average score from the sentence value dictionary\n",
    "    :rtype: int\n",
    "    \"\"\"\n",
    "    sumValues = 0\n",
    "    for entry in sentenceValue:\n",
    "        sumValues += sentenceValue[entry]\n",
    "\n",
    "    # Average value of a sentence from original summary_text\n",
    "    average = (sumValues / len(sentenceValue))\n",
    "\n",
    "    return average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _generate_summary(sentences, sentenceValue, threshold):\n",
    "    sentence_count = 0\n",
    "    summary = ''\n",
    "\n",
    "    for sentence in sentences:\n",
    "        if sentence[:15] in sentenceValue and sentenceValue[sentence[:15]] >= (threshold):\n",
    "            summary += \" \" + sentence\n",
    "            sentence_count += 1\n",
    "\n",
    "    # TODO: check if the sentences in the summarization is in the original order of occurrence.\n",
    "\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/yaoyu/Desktop/python/project/News_content\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('Raw Data/News_content')\n",
    "print (os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(text, keep_most=False):\n",
    "    \"\"\"\n",
    "    Helper function to remove html, unneccessary spaces and punctuation.\n",
    "    Args:\n",
    "        text: String.\n",
    "        keep_most: Boolean. depending if True or False, we either\n",
    "                   keep only letters and numbers or also other characters.\n",
    "\n",
    "    Returns:\n",
    "        processed text.\n",
    "\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    text = fixup(text)\n",
    "    text = re.sub(r\"<br />\", \" \", text)\n",
    "    if keep_most:\n",
    "        text = re.sub(r\"[^a-z0-9%!?.,:()/]\", \" \", text)\n",
    "    else:\n",
    "        text = re.sub(r\"[^a-z0-9]\", \" \", text)\n",
    "    text = re.sub(r\"    \", \" \", text)\n",
    "    text = re.sub(r\"   \", \" \", text)\n",
    "    text = re.sub(r\"  \", \" \", text)\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "\n",
    "def fixup(x):\n",
    "    re1 = re.compile(r'  +')\n",
    "    x = x.replace('#39;', \"'\").replace('amp;', '&').replace('#146;', \"'\").replace(\n",
    "        'nbsp;', ' ').replace('#36;', '$').replace('\\\\n', \"\\n\").replace('quot;', \"'\").replace(\n",
    "        '<br />', \"\\n\").replace('\\\\\"', '\"').replace('<unk>', 'u_n').replace(' @.@ ', '.').replace(\n",
    "        ' @-@ ', '-').replace('\\\\', ' \\\\ ')\n",
    "    return re1.sub(' ', html.unescape(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fids = my_corpus.fileids()\n",
    "result=[]\n",
    "for i in fids:\n",
    "    with open(i,'r') as file:\n",
    "        data = file.read().replace('\\n', '')\n",
    "        data = re.sub(r'(?<=\\.)[^.]*$', \"\",data)\n",
    "        sentences = sent_tokenize(data)\n",
    "        total_documents = len(sentences)\n",
    "        freq_matrix = _create_frequency_matrix(sentences)\n",
    "        tf_matrix = _create_tf_matrix(freq_matrix)\n",
    "        count_doc_per_words = _create_documents_per_words(freq_matrix)\n",
    "        idf_matrix=_create_idf_matrix(freq_matrix, count_doc_per_words, total_documents)\n",
    "        tf_idf_matrix = _create_final_matrix(tf_matrix, idf_matrix)\n",
    "        sentence_scores = _score_sentences(tf_idf_matrix)\n",
    "        threshold = _find_average_score(sentence_scores)\n",
    "        summary = _generate_summary(sentences, sentence_scores, 1.3 * threshold)\n",
    "        Summary=i+summary\n",
    "        result.append(Summary)\n",
    "        \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame()\n",
    "df[\"summary\"]=result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "NO=[]\n",
    "SU=[]\n",
    "for h in df[\"summary\"]:\n",
    "    no=h.split(\" \",1)[0]\n",
    "    su=h.split(\" \",1)[1:]\n",
    "    NO.append(no)\n",
    "    SU.append(su)\n",
    "df[\"NO.\"]=NO\n",
    "df[\"summary\"]=SU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnsTitles = ['NO.', 'summary']\n",
    "\n",
    "df = df.reindex(columns=columnsTitles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NO.</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>145607.txt</td>\n",
       "      <td>[Constant whispers of the US leaving or defund...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>145609.txt</td>\n",
       "      <td>[Imagine the scenario. Ludicrous, right? It ce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>145610.txt</td>\n",
       "      <td>[The Guardian US Politics Minute catches you u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>145611.txt</td>\n",
       "      <td>[” “To me the kangaroos look like Mr and Mrs M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>145612.txt</td>\n",
       "      <td>[It’s no wonder a number of clubs are interest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>145613.txt</td>\n",
       "      <td>[It’s hard to think of a situation in which it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>145615.txt</td>\n",
       "      <td>[”  He said he had already killed several peop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>145616.txt</td>\n",
       "      <td>[British planes were among those operating in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>145618.txt</td>\n",
       "      <td>[He had campaigned for LGBT rights within the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>145619.txt</td>\n",
       "      <td>[Court officials say they cannot find addition...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>145620.txt</td>\n",
       "      <td>[It’s a lot. “I’ve never returned like that in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>145621.txt</td>\n",
       "      <td>[“This sustainability revolution has the bread...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>145622.txt</td>\n",
       "      <td>[“He will be brought to justice. Clayton was m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>145623.txt</td>\n",
       "      <td>[But now what I do and care about has come und...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>145624.txt</td>\n",
       "      <td>[“The Democrats wanted him out three months ag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>145625.txt</td>\n",
       "      <td>[And   contracts for members of his family nee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>145626.txt</td>\n",
       "      <td>[But the conditions were bad, with rain, heavy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>145627.txt</td>\n",
       "      <td>[Especially for the Truth part.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>145628.txt</td>\n",
       "      <td>[Nevertheless it is hoped that half a century ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>145629.txt</td>\n",
       "      <td>[“I was horrified. She noted that the highly c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>145630.txt</td>\n",
       "      <td>[I congratulate Jeremy Corbyn for running a ve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>145632.txt</td>\n",
       "      <td>[The psychological effect on survivors or obse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>145634.txt</td>\n",
       "      <td>[Keys are exchanged between users to guarantee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>145635.txt</td>\n",
       "      <td>[Yet the perception of   deportations is, for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>145636.txt</td>\n",
       "      <td>[His father was an industrialist. What will it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>145637.txt</td>\n",
       "      <td>[SecureDrop records nothing else about you. Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>145638.txt</td>\n",
       "      <td>[As an American, now I’m forbidden to leave my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>145639.txt</td>\n",
       "      <td>[The pipeline’s operating company, TransCanada...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>145640.txt</td>\n",
       "      <td>[“At present I am not convinced that the defen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>145641.txt</td>\n",
       "      <td>[Sharapova, who struggled with her serve all e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38278</th>\n",
       "      <td>26496.txt</td>\n",
       "      <td>[Updated casualty numbers were later reported ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38279</th>\n",
       "      <td>26497.txt</td>\n",
       "      <td>[“They were all having breakfast inside their ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38280</th>\n",
       "      <td>26498.txt</td>\n",
       "      <td>[A lot of the food that I transfer from fork t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38281</th>\n",
       "      <td>26500.txt</td>\n",
       "      <td>[She was 41. When the science content develope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38282</th>\n",
       "      <td>26503.txt</td>\n",
       "      <td>[We will outmatch them at every pass and outla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38283</th>\n",
       "      <td>26507.txt</td>\n",
       "      <td>[No president has undone a predecessor’s desig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38284</th>\n",
       "      <td>26508.txt</td>\n",
       "      <td>[For anyone who loves the spotlight, mothering...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38285</th>\n",
       "      <td>26509.txt</td>\n",
       "      <td>[It has approved fewer than half of those requ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38286</th>\n",
       "      <td>26510.txt</td>\n",
       "      <td>[She stalks it. “We’re walking out the door wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38287</th>\n",
       "      <td>26512.txt</td>\n",
       "      <td>[It has drawn condemnations from many Republic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38288</th>\n",
       "      <td>26513.txt</td>\n",
       "      <td>[But early optimism that this would be an easy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38289</th>\n",
       "      <td>26515.txt</td>\n",
       "      <td>[” Lipsyte and others objected to the policy. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38290</th>\n",
       "      <td>26516.txt</td>\n",
       "      <td>[The new approach did not last long. Trump, wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38291</th>\n",
       "      <td>26517.txt</td>\n",
       "      <td>[The group has pledged allegiance to the Islam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38292</th>\n",
       "      <td>26518.txt</td>\n",
       "      <td>[6 Billion in Financing. 5 Billion Cash Infusi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38293</th>\n",
       "      <td>26519.txt</td>\n",
       "      <td>[Still, the decision to tell it resonates far ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38294</th>\n",
       "      <td>26520.txt</td>\n",
       "      <td>[Yet a number of senators were demanding chang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38295</th>\n",
       "      <td>26521.txt</td>\n",
       "      <td>[He was 87. But he was defined not so much by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38296</th>\n",
       "      <td>26522.txt</td>\n",
       "      <td>[And he did not wait to do it. “There’s no way...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38297</th>\n",
       "      <td>26523.txt</td>\n",
       "      <td>[“Now it’s just you and me. This was his secon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38298</th>\n",
       "      <td>26524.txt</td>\n",
       "      <td>[What are the big takeaways? The    polls were...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38299</th>\n",
       "      <td>26525.txt</td>\n",
       "      <td>[The discussion may include spoilers. WESLEY M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38300</th>\n",
       "      <td>26527.txt</td>\n",
       "      <td>[The implication was simple. Instead of Google...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38301</th>\n",
       "      <td>26530.txt</td>\n",
       "      <td>[When did kids suddenly acquire travel plannin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38302</th>\n",
       "      <td>26532.txt</td>\n",
       "      <td>[He set no personal best in any event in Rio. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38303</th>\n",
       "      <td>26533.txt</td>\n",
       "      <td>[“Plans are in place, but we need the agreemen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38304</th>\n",
       "      <td>26534.txt</td>\n",
       "      <td>[2 passed has eased. But the fight is not over...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38305</th>\n",
       "      <td>26536.txt</td>\n",
       "      <td>[Instead, the predominant feeling here in the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38306</th>\n",
       "      <td>26537.txt</td>\n",
       "      <td>[But his boss, Mr. Obama, voiced skepticism. I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38307</th>\n",
       "      <td>26538.txt</td>\n",
       "      <td>[It embarked on a    review of how discriminat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38308 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              NO.                                            summary\n",
       "0      145607.txt  [Constant whispers of the US leaving or defund...\n",
       "1      145609.txt  [Imagine the scenario. Ludicrous, right? It ce...\n",
       "2      145610.txt  [The Guardian US Politics Minute catches you u...\n",
       "3      145611.txt  [” “To me the kangaroos look like Mr and Mrs M...\n",
       "4      145612.txt  [It’s no wonder a number of clubs are interest...\n",
       "5      145613.txt  [It’s hard to think of a situation in which it...\n",
       "6      145615.txt  [”  He said he had already killed several peop...\n",
       "7      145616.txt  [British planes were among those operating in ...\n",
       "8      145618.txt  [He had campaigned for LGBT rights within the ...\n",
       "9      145619.txt  [Court officials say they cannot find addition...\n",
       "10     145620.txt  [It’s a lot. “I’ve never returned like that in...\n",
       "11     145621.txt  [“This sustainability revolution has the bread...\n",
       "12     145622.txt  [“He will be brought to justice. Clayton was m...\n",
       "13     145623.txt  [But now what I do and care about has come und...\n",
       "14     145624.txt  [“The Democrats wanted him out three months ag...\n",
       "15     145625.txt  [And   contracts for members of his family nee...\n",
       "16     145626.txt  [But the conditions were bad, with rain, heavy...\n",
       "17     145627.txt                   [Especially for the Truth part.]\n",
       "18     145628.txt  [Nevertheless it is hoped that half a century ...\n",
       "19     145629.txt  [“I was horrified. She noted that the highly c...\n",
       "20     145630.txt  [I congratulate Jeremy Corbyn for running a ve...\n",
       "21     145632.txt  [The psychological effect on survivors or obse...\n",
       "22     145634.txt  [Keys are exchanged between users to guarantee...\n",
       "23     145635.txt  [Yet the perception of   deportations is, for ...\n",
       "24     145636.txt  [His father was an industrialist. What will it...\n",
       "25     145637.txt  [SecureDrop records nothing else about you. Th...\n",
       "26     145638.txt  [As an American, now I’m forbidden to leave my...\n",
       "27     145639.txt  [The pipeline’s operating company, TransCanada...\n",
       "28     145640.txt  [“At present I am not convinced that the defen...\n",
       "29     145641.txt  [Sharapova, who struggled with her serve all e...\n",
       "...           ...                                                ...\n",
       "38278   26496.txt  [Updated casualty numbers were later reported ...\n",
       "38279   26497.txt  [“They were all having breakfast inside their ...\n",
       "38280   26498.txt  [A lot of the food that I transfer from fork t...\n",
       "38281   26500.txt  [She was 41. When the science content develope...\n",
       "38282   26503.txt  [We will outmatch them at every pass and outla...\n",
       "38283   26507.txt  [No president has undone a predecessor’s desig...\n",
       "38284   26508.txt  [For anyone who loves the spotlight, mothering...\n",
       "38285   26509.txt  [It has approved fewer than half of those requ...\n",
       "38286   26510.txt  [She stalks it. “We’re walking out the door wh...\n",
       "38287   26512.txt  [It has drawn condemnations from many Republic...\n",
       "38288   26513.txt  [But early optimism that this would be an easy...\n",
       "38289   26515.txt  [” Lipsyte and others objected to the policy. ...\n",
       "38290   26516.txt  [The new approach did not last long. Trump, wo...\n",
       "38291   26517.txt  [The group has pledged allegiance to the Islam...\n",
       "38292   26518.txt  [6 Billion in Financing. 5 Billion Cash Infusi...\n",
       "38293   26519.txt  [Still, the decision to tell it resonates far ...\n",
       "38294   26520.txt  [Yet a number of senators were demanding chang...\n",
       "38295   26521.txt  [He was 87. But he was defined not so much by ...\n",
       "38296   26522.txt  [And he did not wait to do it. “There’s no way...\n",
       "38297   26523.txt  [“Now it’s just you and me. This was his secon...\n",
       "38298   26524.txt  [What are the big takeaways? The    polls were...\n",
       "38299   26525.txt  [The discussion may include spoilers. WESLEY M...\n",
       "38300   26527.txt  [The implication was simple. Instead of Google...\n",
       "38301   26530.txt  [When did kids suddenly acquire travel plannin...\n",
       "38302   26532.txt  [He set no personal best in any event in Rio. ...\n",
       "38303   26533.txt  [“Plans are in place, but we need the agreemen...\n",
       "38304   26534.txt  [2 passed has eased. But the fight is not over...\n",
       "38305   26536.txt  [Instead, the predominant feeling here in the ...\n",
       "38306   26537.txt  [But his boss, Mr. Obama, voiced skepticism. I...\n",
       "38307   26538.txt  [It embarked on a    review of how discriminat...\n",
       "\n",
       "[38308 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"4a. TFIDF_Summary.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
